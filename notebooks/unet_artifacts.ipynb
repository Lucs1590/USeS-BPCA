{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucs1590/USeS-BPCA/blob/main/notebooks/u_net_bpca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU_UgOsYWQ68"
      },
      "source": [
        "# U-net-like with Oxford-IIIT Pet Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uHZjOWbWQ7C"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt9oCr-xWQ7D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "import xplique\n",
        "from xplique.plots import plot_attributions\n",
        "from xplique.utils_functions.segmentation import get_connected_zone, get_in_out_border, get_common_border\n",
        "from xplique.metrics import Deletion, MuFidelity, Insertion, AverageStability\n",
        "from xplique.plots.metrics import barplot\n",
        "from xplique.attributions import (Saliency, GradientInput, IntegratedGradients, SmoothGrad, VarGrad, SquareGrad,\n",
        "                                  Occlusion, Rise, SobolAttributionMethod, HsicAttributionMethod)\n",
        "\n",
        "from xplique.plots import plot_attributions\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tpm-dkSWQ7H",
        "outputId": "fc257172-b67b-40ee-c7eb-7f23d0542fec"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "np.random.seed(77)\n",
        "tf.random.set_seed(77)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNDeybWWQ7I"
      },
      "source": [
        "## Constant Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0Aze5D7WQ7I"
      },
      "outputs": [],
      "source": [
        "HEIGHT, WIDTH = 256, 256\n",
        "NUM_CLASSES = 3  # background, foreground, boundary\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jrpRYaAWQ7J"
      },
      "source": [
        "## Dataset\n",
        "Download and applying transformations to the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNe-V7VKWQ7K",
        "outputId": "2a07c04e-6f23-4299-f2d9-dd45698dbbcd"
      },
      "outputs": [],
      "source": [
        "dataset, info = tfds.load(\n",
        "    'oxford_iiit_pet:3.*.*',\n",
        "    with_info=True,\n",
        "    shuffle_files=True,\n",
        "    data_dir='/home/hinton/brito/datasets/'\n",
        ")\n",
        "\n",
        "print(info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes_dict = {str(i): [label] for i, label in enumerate(info.features['label'].names)}\n",
        "print(classes_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq2H9FWiWQ7L"
      },
      "outputs": [],
      "source": [
        "def resize(input_image, input_mask):\n",
        "    input_image = tf.image.resize(\n",
        "        input_image,\n",
        "        (HEIGHT, WIDTH),\n",
        "        method=\"nearest\"\n",
        "    )\n",
        "    input_mask = tf.image.resize(input_mask, (HEIGHT, WIDTH), method=\"nearest\")\n",
        "\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRuGfCh8WQ7M"
      },
      "outputs": [],
      "source": [
        "def normalize(input_image, input_mask):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask -= 1\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bopTlkpJWQ7N"
      },
      "outputs": [],
      "source": [
        "def load_image_test(datapoint):\n",
        "    input_image = datapoint[\"image\"]\n",
        "    input_mask = datapoint[\"segmentation_mask\"]\n",
        "    input_image, input_mask = resize(input_image, input_mask)\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJCqx1FvWQ7N",
        "outputId": "e359ba66-1245-42a6-de09-22b31bd75383"
      },
      "outputs": [],
      "source": [
        "test_dataset = dataset[\"test\"].take(1632).map(load_image_test, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAOBLLDWQ7N"
      },
      "outputs": [],
      "source": [
        "validation_batches = test_dataset.take(963).batch(BATCH_SIZE)\n",
        "test_batches = test_dataset.skip(963).take(669).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OzDY-mJWQ7N"
      },
      "outputs": [],
      "source": [
        "def display(display_list, name=None):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = [\"Imagem de Entrada\", \"Máscara\", \"Máscara Predita\"]\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    if name:\n",
        "        plt.savefig(f\"{name}.png\", format=\"png\", dpi=300,\n",
        "                    bbox_inches='tight', pad_inches=0.0, transparent=True)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gnsXV4yjKoN"
      },
      "source": [
        "## BPCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVCY3TfjMjU"
      },
      "outputs": [],
      "source": [
        "class BPCAPooling(tf.keras.layers.Layer):\n",
        "    def __init__(self, pool_size=2, stride=2, n_components=1, expected_shape=None, **kwargs):\n",
        "        super(BPCAPooling, self).__init__(**kwargs)\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "        self.n_components = n_components\n",
        "        self.expected_shape = expected_shape\n",
        "\n",
        "        self.patch_size = [1, self.pool_size, self.pool_size, 1]\n",
        "        self.strides = [1, self.stride, self.stride, 1]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(BPCAPooling, self).build(input_shape)\n",
        "\n",
        "    @tf.function\n",
        "    def bpca_pooling(self, feature_map):\n",
        "        # Compute the region of interest\n",
        "        h, w, c = self.expected_shape  # block_height, block_width, block_channels\n",
        "        d = c // (self.pool_size * self.pool_size)  # block_depth\n",
        "\n",
        "        # Create blocks (patches)\n",
        "        data = tf.reshape(feature_map, [1, h, w, c])\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=data,\n",
        "            sizes=self.patch_size,\n",
        "            strides=self.strides,\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding='VALID'\n",
        "        )\n",
        "        patches = tf.reshape(\n",
        "            patches,\n",
        "            [h*w*d, self.pool_size * self.pool_size]\n",
        "        )\n",
        "\n",
        "        # Normalize the data by subtracting the mean and dividing by the standard deviation\n",
        "        mean = tf.reduce_mean(patches, axis=0)\n",
        "        std = tf.math.reduce_std(patches, axis=0)\n",
        "        patches = (patches - mean) / std\n",
        "        patches = tf.where(tf.math.is_nan(patches), 0.0, patches)\n",
        "        \n",
        "        # Perform the Singular Value Decomposition (SVD) on the data\n",
        "        _, _, v = tf.linalg.svd(patches)\n",
        "\n",
        "        # Extract the first n principal components from the matrix v\n",
        "        pca_components = v[:, :self.n_components]\n",
        "\n",
        "        # Perform the PCA transformation on the data\n",
        "        transformed_patches = tf.matmul(patches, pca_components)\n",
        "\n",
        "        \n",
        "        return tf.reshape(transformed_patches, [h // self.pool_size, w // self.pool_size, c])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pooled = tf.vectorized_map(self.bpca_pooling, inputs)\n",
        "        return pooled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_iou(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true > 0.5, tf.int32) \n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.int32)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
        "    iou = intersection / union\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "    smooth = 1.0  # to avoid division by zero\n",
        "    y_true = tf.cast(y_true > 0.5, tf.float32)\n",
        "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
        "    dice_coefficient = (2.0 * intersection + smooth) / (union + smooth)\n",
        "    return dice_coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pixel_accuracy(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.dtypes.float64)\n",
        "    y_pred = tf.cast(y_pred, tf.dtypes.float64)\n",
        "    return tf.reduce_mean(tf.cast(\n",
        "        tf.equal(y_true, y_pred),\n",
        "        tf.float32\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "ArdS4_e1WQ7S",
        "outputId": "e490f9ff-62b6-424b-f73d-9ff1f7a8fe9e"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(model_history, output_dir):\n",
        "    if 'loss' in model_history.columns:\n",
        "        plt.plot(model_history['loss'])\n",
        "        plt.plot(model_history['val_loss'])\n",
        "        plt.legend(['train', 'test'])\n",
        "        plt.title('loss')\n",
        "        plt.legend([\"Loss\", \"Loss de Validação\"])\n",
        "        plt.savefig(f\"{output_dir}loss.png\", dpi=300, format=\"png\")\n",
        "\n",
        "    if 'accuracy' in model_history.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(model_history[\"accuracy\"])\n",
        "        plt.plot(model_history['val_accuracy'])\n",
        "        plt.legend(['train', 'test'])\n",
        "        plt.title('accuracy')\n",
        "        plt.legend([\"Acurácia\", \"Acurácia de Validação\"])\n",
        "        plt.savefig(f\"{output_dir}accuracy.png\", dpi=300, format=\"png\")\n",
        "\n",
        "    if 'mean_iou' in model_history.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(model_history[\"mean_iou\"])\n",
        "        plt.plot(model_history['val_mean_iou'])\n",
        "        plt.legend(['train', 'test'])\n",
        "        plt.title('mean_iou')\n",
        "        plt.legend([\"MeanIoU\", \"MeanIoU de Validação\"])\n",
        "        plt.savefig(f\"{output_dir}mean_iou.png\", dpi=300, format=\"png\")\n",
        "\n",
        "    if 'dice_coefficient' in model_history.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(model_history[\"dice_coefficient\"])\n",
        "        plt.plot(model_history['val_dice_coefficient'])\n",
        "        plt.legend(['train', 'test'])\n",
        "        plt.title('dice_coefficient')\n",
        "        plt.legend([\"DiceCoefficient\", \"DiceCoefficient de Validação\"])\n",
        "        plt.savefig(f\"{output_dir}dice_coefficient.png\", dpi=300, format=\"png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HW_qEluWQ7S"
      },
      "outputs": [],
      "source": [
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelWrapper(tf.keras.Model):\n",
        "    # WARNING: `torch.nn.Module` specific to pytorch\n",
        "    # `tf.keras.Model` instead for tensorflow models\n",
        "\n",
        "    def __init__(self, model):\n",
        "        super(ModelWrapper, self).__init__()\n",
        "        self.model = model.eval()\n",
        "\n",
        "    def __call__(self, torch_inputs):\n",
        "        # this method should change depending on the model\n",
        "        return self.model(torch_inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_patch_segment(image, model, output_dir):\n",
        "    categories = ['Pet', 'Fundo', 'Contorno']\n",
        "\n",
        "    alpha = 0.6\n",
        "    colormap = np.asarray(plt.get_cmap('tab20').colors)\n",
        "    idx_to_class = {i: c for (i, c) in enumerate(categories)}\n",
        "\n",
        "    # Use the model to predict the segmentation mask\n",
        "    pred_mask = model.predict(image[tf.newaxis, ...])\n",
        "    pred_seg = create_mask(pred_mask)\n",
        "\n",
        "    # Initialize an empty 3D array (`color_seg`) with the same height and width as the predicted segmentation map, and 3 color channels.\n",
        "    color_seg = np.zeros((pred_seg.shape[0], pred_seg.shape[1], 3))\n",
        "\n",
        "    # Loop over each color in the colormap. For each color, update the corresponding pixels in `color_seg` where the predicted label matches the current label. If there are any pixels with the current label in the predicted segmentation map, create a patch object with the current color and label, and append it to the `handles` list for the legend.\n",
        "    handles = []\n",
        "    # Limit the colormap to the number of categories\n",
        "    for (i, color) in enumerate(colormap[:len(categories)]):\n",
        "        # Update the pixels in `color_seg` where the predicted label matches the current label\n",
        "        color_seg[pred_seg[:, :, 0] == i] = color\n",
        "\n",
        "        # Create a patch object with the current color and label\n",
        "        patch = mpatches.Patch(color=color, label=idx_to_class[i])\n",
        "        handles.append(patch)\n",
        "\n",
        "    # Overlay the color-coded segmentation map (`color_seg`) on the original image with a certain transparency level (`alpha`).\n",
        "    # And Display the overlaid image using `plt.imshow()`, add a legend using `plt.legend()` with the handles created earlier, and add a grid using `plt.grid()`.\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(color_seg, alpha=alpha)\n",
        "    plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid()\n",
        "    plt.savefig(f\"{output_dir}overlayed_segmentation.png\", format=\"png\",\n",
        "                dpi=300, bbox_inches='tight', pad_inches=0.0, transparent=True)\n",
        "\n",
        "    return pred_seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_segmentation_zone(image, pred_seg, model, output_dir):\n",
        "    alpha = 0.6\n",
        "\n",
        "    pet_zone_targets = get_connected_zone(\n",
        "        pred_seg,\n",
        "        coordinates=(250, 250)\n",
        "    )[tf.newaxis]\n",
        "\n",
        "    # compute explanation on this zone via HSIC method\n",
        "    explainer = HsicAttributionMethod(\n",
        "        model,\n",
        "        operator=xplique.Tasks.SEMANTIC_SEGMENTATION,\n",
        "        nb_design=750,\n",
        "        grid_size=12,\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "    explanation = explainer.explain(\n",
        "        image[tf.newaxis],\n",
        "        pet_zone_targets\n",
        "    )\n",
        "\n",
        "    # add mask to image for visualization (optional)\n",
        "    pet_mask = tf.cast(pet_zone_targets != 0, tf.float32)\n",
        "    image_with_mask = (1 - alpha) * image + alpha * pet_mask\n",
        "\n",
        "    # visualize explanation\n",
        "    plot_attributions(\n",
        "        explanation,\n",
        "        image_with_mask,\n",
        "        img_size=4.,\n",
        "        cmap='jet',\n",
        "        alpha=0.3,\n",
        "        absolute_value=False,\n",
        "        clip_percentile=0.5\n",
        "    )\n",
        "    # save image adjusted\n",
        "    plt.savefig(f\"{output_dir}overlayed_segmentation_zone.png\", format=\"png\",\n",
        "                dpi=300, bbox_inches='tight', pad_inches=0.0, transparent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_border_segmentations(image, predictions, model, output_dir):\n",
        "    assert len(predictions.shape) == 3\n",
        "\n",
        "    # specify the coordinate of a point in the zone to explain\n",
        "    pet_coordinates = (200, 50)\n",
        "    background_coordinates = (200, 50)\n",
        "\n",
        "    # compute the `targets` parameter to explain the specified zones\n",
        "    pet_zone_predictions = get_connected_zone(predictions, pet_coordinates)\n",
        "    background_zone_predictions = get_connected_zone(\n",
        "        predictions, background_coordinates)\n",
        "\n",
        "    # compute the `targets` parameter to explain the border of the specified zones\n",
        "    pet_borders_predictions = get_in_out_border(pet_zone_predictions)\n",
        "    background_borders_predictions = get_in_out_border(\n",
        "        background_zone_predictions)\n",
        "\n",
        "    # compute the `targets` parameter to explain the border between two specified zones\n",
        "    common_border_predictions = get_common_border(\n",
        "        pet_zone_predictions,\n",
        "        background_borders_predictions\n",
        "    )\n",
        "\n",
        "    # tile and stack tensors to call the method once by image\n",
        "    images = tf.tile(image[tf.newaxis], (5, 1, 1, 1))\n",
        "    inputs = tf.tile(image[tf.newaxis], (5, 1, 1, 1))\n",
        "\n",
        "    targets = tf.stack([\n",
        "        pet_zone_predictions,\n",
        "        background_zone_predictions,\n",
        "        pet_borders_predictions,\n",
        "        background_zone_predictions,\n",
        "        common_border_predictions\n",
        "    ])\n",
        "\n",
        "    # add the zone mask to the image to visualize\n",
        "    mask_alpha = 0.5\n",
        "    masks = tf.expand_dims(tf.cast(tf.reduce_any(\n",
        "        targets != 0, axis=-1), tf.float32), -1)\n",
        "    images_with_masks = (1 - mask_alpha) * images + mask_alpha * masks\n",
        "\n",
        "    explainers = {\n",
        "        Saliency: {},\n",
        "        GradientInput: {},\n",
        "        IntegratedGradients: {\"steps\": 20},\n",
        "        SmoothGrad: {\"nb_samples\": 50, \"noise\": 0.75},\n",
        "        VarGrad: {\"nb_samples\": 50, \"noise\": 0.75},\n",
        "        SquareGrad: {\"nb_samples\": 100, \"noise\": 0.5},\n",
        "        Occlusion: {\"patch_size\": 40, \"patch_stride\": 10, \"occlusion_value\": 0},\n",
        "        Rise: {\"nb_samples\": 4000, \"grid_size\": 13},\n",
        "        SobolAttributionMethod: {\"nb_design\": 32, \"grid_size\": 13},\n",
        "        HsicAttributionMethod: {\"nb_design\": 1500, \"grid_size\": 13}\n",
        "    }\n",
        "\n",
        "    explanations = {}\n",
        "    for explainer_class, params in explainers.items():\n",
        "        tf.keras.backend.clear_session()\n",
        "        plt.clf()\n",
        "        print(explainer_class.__name__)\n",
        "\n",
        "        # instanciate explainer\n",
        "        explainer = explainer_class(\n",
        "            model,\n",
        "            operator=xplique.Tasks.SEMANTIC_SEGMENTATION,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            **params\n",
        "        )\n",
        "\n",
        "        # compute explanations\n",
        "        explanation = explainer(inputs, targets)\n",
        "\n",
        "        # show explanations for a method\n",
        "        plot_attributions(\n",
        "            explanation,\n",
        "            images_with_masks,\n",
        "            img_size=4.,\n",
        "            cols=images.shape[0],\n",
        "            cmap='jet',\n",
        "            alpha=0.3,\n",
        "            absolute_value=False,\n",
        "            clip_percentile=0.5\n",
        "        )\n",
        "        plt.show()\n",
        "        plt.savefig(f\"{output_dir}{explainer_class.__name__}.png\", format=\"png\",\n",
        "                    dpi=300, bbox_inches='tight', pad_inches=0.0, transparent=True)\n",
        "\n",
        "        # keep explanations in memory for metrics\n",
        "        explanations[explainer_class.__name__] = explanation\n",
        "\n",
        "    return explanations, inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_xai_metrics(explanations, inputs, targets, model, output_dir):\n",
        "    metrics = {}\n",
        "    explanations_metrics = {\n",
        "        Deletion: {\"baseline_mode\": 0, \"steps\": 10, \"max_percentage_perturbed\": 0.5},\n",
        "        MuFidelity: {\"baseline_mode\": 0, \"nb_samples\": 5, \"subset_percent\": 0.2, \"grid_size\": 13},\n",
        "        Insertion: {\"baseline_mode\": 0, \"steps\": 10,\n",
        "                    \"max_percentage_perturbed\": 0.5}\n",
        "    }\n",
        "    for metric_class, params in explanations_metrics.items():\n",
        "        tf.keras.backend.clear_session()\n",
        "        plt.clf()\n",
        "\n",
        "        # instanciate the metric\n",
        "        metric = metric_class(\n",
        "            model,\n",
        "            np.array(inputs[:3]),\n",
        "            np.array(targets[:3]),\n",
        "            operator=xplique.Tasks.SEMANTIC_SEGMENTATION,\n",
        "            activation=\"softmax\",\n",
        "            batch_size=BATCH_SIZE,\n",
        "            **params\n",
        "        )\n",
        "\n",
        "        # iterate on methods explanations\n",
        "        metrics[metric_class.__name__] = {}\n",
        "        for method, explanation in explanations.items():\n",
        "            metrics[metric_class.__name__][method] = metric(explanation[:3])\n",
        "\n",
        "    barplot(metrics, sort_metric=\"Deletion\", ascending=\"True\")\n",
        "    plt.show()\n",
        "    plt.savefig(f\"{output_dir}barplot.png\", format=\"png\",\n",
        "                dpi=300, bbox_inches='tight', pad_inches=0.0, transparent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Selection and Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# take a random image from the test dataset\n",
        "MODELS_PATH = \"/home/hinton/brito/models/\"\n",
        "OUTPUTS_PATH = \"/home/hinton/brito/outputs/\"\n",
        "\n",
        "None if os.path.isdir(OUTPUTS_PATH) else os.mkdir(OUTPUTS_PATH)\n",
        "\n",
        "images = []\n",
        "masks = []\n",
        "for image, mask in test_batches.take(3):\n",
        "    images.append(image)\n",
        "    masks.append(mask)\n",
        "\n",
        "for model_path in glob.glob(f'{MODELS_PATH}*.h5'):\n",
        "    model = load_model(model_path, custom_objects={'mean_iou': mean_iou, 'dice_coefficient': dice_coefficient, 'pixel_accuracy': pixel_accuracy, 'BPCAPooling': BPCAPooling})\n",
        "    model_history = pd.read_csv(f'{MODELS_PATH}{model_path.split(\"/\")[-1].replace(\".h5\", \".csv\")}')\n",
        "    \n",
        "    print(f\"Model: {model_path.split('/')[-1]}\")\n",
        "    output_dir = f'{OUTPUTS_PATH}{model_path.split(\"/\")[-1].replace(\".h5\", \"\")}/'\n",
        "    None if os.path.isdir(output_dir) else os.mkdir(output_dir)\n",
        "\n",
        "    try:\n",
        "        loss, accuracy, m_iou, dice = model.evaluate(validation_batches)\n",
        "        print(f\"Loss: {loss}, Accuracy: {accuracy}, Mean IoU: {m_iou}, Dice Coefficient: {dice}\")\n",
        "        del loss, accuracy, m_iou, dice\n",
        "    except ValueError:\n",
        "        loss, accuracy = model.evaluate(validation_batches)\n",
        "        print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
        "        del loss, accuracy\n",
        "\n",
        "    plot_metrics(model_history, output_dir)\n",
        "\n",
        "    for i, (image, mask) in enumerate(zip(images, masks)):\n",
        "        pred_mask = model.predict(image)\n",
        "        display([image[0], mask[0], create_mask(pred_mask)], name=f\"{output_dir}image_{i}\")\n",
        "        segmentation_predict = run_patch_segment(image[0], model, f\"{output_dir}image_{i}_\")\n",
        "        plot_segmentation_zone(image[0], segmentation_predict, model, f\"{output_dir}image_{i}_\")\n",
        "        explanations, inputs, targets = run_border_segmentations(image[0], pred_mask[0], model, f\"{output_dir}image_{i}_\")\n",
        "        plot_xai_metrics(explanations, inputs, targets, model, f\"{output_dir}image_{i}_\")\n",
        "\n",
        "        del segmentation_predict, explanations, inputs, targets, image, mask, pred_mask\n",
        "        plt.clf()\n",
        "        plt.close('all')\n",
        "\n",
        "    del model, model_history, output_dir\n",
        "    tf.keras.backend.clear_session()\n",
        "    tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case:\n",
        "\n",
        "- Deletion: lower is better\n",
        "- Mufidelity: higher is better\n",
        "- Insertion: higher is better\n",
        "- AverageStability: lower is better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zip OUTPUTS_PATH without lossing the folder structure and data\n",
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file))\n",
        "\n",
        "zipf = zipfile.ZipFile(f'{OUTPUTS_PATH}outputs.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "zipdir(OUTPUTS_PATH, zipf)\n",
        "zipf.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "# zip OUTPUTS_PATH without lossing the folder structure and data\n",
        "\n",
        "shutil.make_archive(f'{OUTPUTS_PATH}outputs2', 'zip', OUTPUTS_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
